<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大模型训练 on Charent的博客</title>
        <link>https://charent.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</link>
        <description>Recent content in 大模型训练 on Charent的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 12 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://charent.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大模型微调出现loss尖峰/尖刺</title>
        <link>https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/</link>
        <pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate>
        
        <guid>https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/</guid>
        <description>&lt;img src="https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/1.png" alt="Featured image of post 大模型微调出现loss尖峰/尖刺" /&gt;&lt;h1 id=&#34;大模型下游任务微调时loss出现尖刺处理办法&#34;&gt;大模型下游任务微调时loss出现尖刺处理办法
&lt;/h1&gt;&lt;p&gt;之前在对大模型进行微调时，loss出现了尖刺，现在想起来就记录一下。&lt;br&gt;
先说一下下游任务，模型的输入是较长的文本（单个样本约&lt;code&gt;4000 tokens&lt;/code&gt;，&lt;code&gt;7000&lt;/code&gt;左右的文本长度），输出是特定格式的文本摘要。&lt;/p&gt;
&lt;p&gt;训练主要硬件配置如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CPU：Intel&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; Xeon&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; Gold 5318Y CPU @ 2.10GHz
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;GPU： &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; * &lt;span style=&#34;color:#ae81ff&#34;&gt;4090&lt;/span&gt; 24G
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;内存：128 GB
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;基座模型及训练的主要参数如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;base model：Qwen2.5-7B-Instruct-GPTQ-Int8
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total batch size: &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lr: 1e-6
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;num_train_epochs: &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lora_rank: &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lora_alpha：16
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lr_scheduler_type：cosine_with_restarts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lr_scheduler_num_cycles：4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;训练方式：用&lt;code&gt;accelerate&lt;/code&gt;的分布式后端&lt;code&gt;FSDP&lt;/code&gt;做数据并行&lt;code&gt;DDP&lt;/code&gt;，训练代码是二次封装的&lt;code&gt;transformers&lt;/code&gt;的&lt;code&gt;Trainer&lt;/code&gt;，数据处理部分是自己写的，对输入的&lt;code&gt;system&lt;/code&gt;、&lt;code&gt;user&lt;/code&gt;部分的&lt;code&gt;token&lt;/code&gt;做了屏蔽，只计算模型回复部分&lt;code&gt;assistant&lt;/code&gt;部分的&lt;code&gt;loss&lt;/code&gt;。然后出现了让广大LLMer头疼的问题：loss尖刺。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/1.png&#34;
	width=&#34;1233&#34;
	height=&#34;482&#34;
	srcset=&#34;https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/1_hu_fbec87b96c24805e.png 480w, https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/1_hu_8c28d464ad33b4b4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;loss&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;255&#34;
		data-flex-basis=&#34;613px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;除了第0个&lt;code&gt;epoch&lt;/code&gt;，每个&lt;code&gt;epoch&lt;/code&gt;的第一个&lt;code&gt;batch&lt;/code&gt;都出现&lt;code&gt;loss&lt;/code&gt;尖刺，尝试跳过每个&lt;code&gt;epoch&lt;/code&gt;的第一个&lt;code&gt;batch&lt;/code&gt;、重新打乱数据，问题依然存在。也试过打印第一个&lt;code&gt;batch&lt;/code&gt;的数据进行检查，但并没有发现异常。&lt;/p&gt;
&lt;p&gt;后面在网上搜到了这篇博客：&lt;a class=&#34;link&#34; href=&#34;https://huggingface.co/blog/zh/deepspeed-to-fsdp-and-back&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugging Face Accelerate 两个后端的故事：FSDP 与 DeepSpeed&lt;/a&gt; 。省流： &lt;code&gt;FSDP&lt;/code&gt; 与 &lt;code&gt;DeepSpeed&lt;/code&gt; 在混合精度处理方面有差异，&lt;code&gt;FSDP&lt;/code&gt;使用较低的学习率可能会导致不收敛。另外考虑到动态学习率的循环次数&lt;code&gt;num_cycles&lt;/code&gt;和&lt;code&gt;num_train_epochs&lt;/code&gt;较接近，可能会对&lt;code&gt;loss&lt;/code&gt;有影响。故对调整以下参数为新的值：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lr: 1e-4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lr_scheduler_num_cycles：8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;问题解决：&lt;br&gt;
&lt;img src=&#34;https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/2.png&#34;
	width=&#34;1226&#34;
	height=&#34;424&#34;
	srcset=&#34;https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/2_hu_46e48045defef277.png 480w, https://charent.github.io/post/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%87%BA%E7%8E%B0loss%E5%B0%96%E5%B3%B0/2_hu_2e74f1c071f6059a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;loss_2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;693px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
