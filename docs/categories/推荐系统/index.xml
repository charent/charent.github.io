<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>推荐系统 on Charent的博客</title>
        <link>https://charent.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</link>
        <description>Recent content in 推荐系统 on Charent的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 26 Dec 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://charent.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>推荐系统衡量方法</title>
        <link>https://charent.github.io/post/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%A1%A1%E9%87%8F%E6%96%B9%E6%B3%95/</link>
        <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
        
        <guid>https://charent.github.io/post/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%A1%A1%E9%87%8F%E6%96%B9%E6%B3%95/</guid>
        <description>&lt;h1 id=&#34;ab-test&#34;&gt;AB Test：
&lt;/h1&gt;&lt;p&gt;A/B 测试是为Web或App界面或流程制作两个（A/B）或多个（A/B/n）版本，在同一时间维度，分别让组成成分相同（相似）的访客群组（目标人群）随机的访问这些版本，收集各群组的用户体验数据和业务数据，最后分析、评估出最好版本，正式采用。&lt;/p&gt;
&lt;h1 id=&#34;点击通过率click-through-ratectr&#34;&gt;点击通过率（Click-through Rate，CTR）:
&lt;/h1&gt;&lt;p&gt;一般指网络广告的点击到达率，即该广告的实际点击次数除以广告的展现量，即clicks/views。反映了网页上某一内容的受关注程度，常常用来衡量广告的吸引程度&lt;/p&gt;
&lt;h1 id=&#34;roc曲线&#34;&gt;ROC曲线
&lt;/h1&gt;&lt;p&gt;接受者操作特性曲线（receiver operating characteristic curve，简称ROC曲线）。曲线的横坐标为假阳性率（False Positive Rate, FPR）&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-math&#34; data-lang=&#34;math&#34;&gt;FPR=\frac {FP} {(FP+TN)}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;N是真实负样本的个数，
FP是N个负样本中被分类器预测为正样本的个数。
纵坐标为真阳性率（True Positive Rate, TPR）&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-math&#34; data-lang=&#34;math&#34;&gt;TPR=\frac {TP}{P}=\frac {TP} {(TP+FN)}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，P是真实正样本的个数，TP是P个正样本中被分类器预测为正样本的个数。&lt;/p&gt;
&lt;h1 id=&#34;auc-roc曲线下方的面积大小&#34;&gt;AUC （ROC曲线下方的面积大小）：
&lt;/h1&gt;&lt;p&gt;AUC（Area Under Curve）被定义为ROC曲线下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。我们往往使用AUC值作为模型的评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好&lt;/p&gt;
</description>
        </item>
        <item>
        <title>存在依赖关系的推荐</title>
        <link>https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</link>
        <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
        
        <guid>https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</guid>
        <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#对于一些简单的for循环用map和lambda优化，加快脚本运行速度， 如&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lines &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : list(eval(x)), lines))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#对于一些经常要判定一个元素是否在某个数组里面的操作，将数组转换为集合，加快查找速度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set(map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], n_movies))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;数据处理部分&#34;&gt;数据处理部分
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;电影间的依赖关系：使用networkx随机生成有向无环图，共生成10个有向无环图，根据生成的图可以生成业务矩阵：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;矩阵的列：vertex, next_job, negative_job, clicked_job, parents
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;一个顶点的next_job生成：
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    1)取该顶点v的孩子顶点，记为v_children
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    2)取该顶点v所有父顶点中孩子顶点，但这些孩子顶点不是v的父顶点,记为v_p_c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    3)v_children和v_p_c取并集，该并集即是next_job
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;一个顶点的negative_job生成：
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    1)取该顶点v所在连通子图的所有顶点v_connect
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    2)在v_connect中删除该顶点v本身，删除v的所有孩子顶点，删除v的所有父顶点以及父顶点的孩子顶点，剩余的顶点记为v_res
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    3)将v_res和其它连通子图（即所有非顶点v所属的连通子图）的所有顶点取并集，该并集即是negative_job
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clicked_job=parents
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p1.png&#34;
	width=&#34;440&#34;
	height=&#34;251&#34;
	srcset=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p1_hu_fe198683cf4ea9aa.png 480w, https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p1_hu_2f9e86d8e97fb9f9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;依赖图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;420px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据处理过程&#34;&gt;数据处理过程
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;电影选取：统计数据集中每部电影被用户交互过的次数，从大到小排序，从交互比较稠密的前200个电影中随机抽取152部。
根据选取出的152部电影选出交互过这些电影是用户，如果用户交互过的所有电影的负样本的交集为空，则不选择该用户；并且，每个用户交互过的电影必须大于4个，防止用户交互信息过于稀疏。&lt;/li&gt;
&lt;li&gt;生成用户行为数据：根据选出的用户和其交互过的电影信息，生成[用户id，业务id，评分，上一次交互id，时间戳] 格式的行为数据，上一层交互id不存在用-1代替，业务id即是152个电影id。&lt;/li&gt;
&lt;li&gt;将选出的电影特征做处理，将电影上映年份、种类处理为one hot向量。
将用户信息的邮政编码归一化处理，将用户的性别、职业、年龄等信息处理为 one hot 向量。&lt;/li&gt;
&lt;li&gt;将电影标题使用bert_as_service生成1x768的句子向量，给定一个在一定单词数在一定范围内的句子，bert as service能生成该句子的1x768的向量。&lt;/li&gt;
&lt;li&gt;编写DataInput类，用于将行为数据中的用户id和用户信息（职业性别等向量）、电影id和电影信息（电影类型、发行年份的one hot向量，bert句子向量等）关联起来，生成一条样本数据。编写next_batc()方法用于生产下一批次的样本数据，作为模型的输入，next_batc()函数用参数isTrain来判断当前的next batch是训练数据还是测试数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;模型部分&#34;&gt;模型部分
&lt;/h4&gt;&lt;p&gt;模型如图所示
&lt;img src=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p2.png&#34;
	width=&#34;1174&#34;
	height=&#34;695&#34;
	srcset=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p2_hu_b1f52d948733733d.png 480w, https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p2_hu_81c91fb078429739.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;模型&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;405px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在忽略batch size的情况下，用户信息的输入tensor为 1x30；正样本的输入tensor为 2 * 796，2是lstm cell输入的max time，即是有2个时间序列，表示电影依赖关系a-&amp;gt;b的序列，796中的768是电影标题的句子向量，剩下的28是电影种类、发行年份的one hot 向量；负样本的输入仅仅是一个电影的信息向量，1x796。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;封装tensorflow的全连接层函数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add_dense&lt;/span&gt;(input_tensor, output_size, layer_name, keep_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;, activation_function&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;, reuse&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;添加一个全连接层。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    输入的tensor，输出的维度，层的名字
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;#获得tensor的列数（shape的第二个维度）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    input_cloumn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_shape()[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;#计算dropout_rate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# dropout_rate = 1.0 - keep_prob&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;variable_scope(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dense_layer_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; layer_name, reuse&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;reuse):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        weights &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_variable(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weights&amp;#39;&lt;/span&gt;, [input_cloumn, output_size], initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;truncated_normal_initializer(stddev&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        biases &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_variable(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;biases&amp;#39;&lt;/span&gt;, [output_size], initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant_initializer(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0001&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        variable_summaries(weights, layer_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_weights&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        variable_summaries(biases, layer_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_biases&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        mul_op &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;matmul(input_tensor, weights) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; biases
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output_tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; activation_function &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output_tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mul_op
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output_tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; activation_function(mul_op)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; keep_prob &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output_tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout(output_tensor, keep_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;keep_prob)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;  output_tensor
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;封装tensorflow的LSTM层函数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add_LSTM&lt;/span&gt;(input_tensor, num_units_per_layer_list, layer_name, keep_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;, reuse&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;添加一个长短期记忆网络。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;input_tensor：输入tensor，[batch_size, max_time, cell.output_size]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;num_units_per_layer_list：LSTM的隐藏单元个数列表
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# drop_rate = 1.0 - keep_prob&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;variable_scope(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lstm_layer_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; layer_name, reuse&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;reuse):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lstm_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; num_units_per_layer_list:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        lstm_cell &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contrib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rnn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BasicLSTMCell(size)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; keep_prob &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            lstm_cell &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contrib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rnn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DropoutWrapper(lstm_cell, output_keep_prob&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;keep_prob)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        lstm_layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(lstm_cell)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(lstm_layers) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        muti_Lstm_cells &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contrib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rnn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MultiRNNCell(lstm_layers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# init_state = muti_Lstm_cells.zero_state(batch_size, dtype=tf.float32)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        _, final_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dynamic_rnn(cell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;muti_Lstm_cells, inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;input_tensor, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;outputs&amp;#39; is a tensor of shape [batch_size, max_time, sequence_length]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;state&amp;#39; is a N-tuple where N is the number of LSTMCells containing a tf.nn.rnn_cell.LSTMStateTuple for each cell&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; final_state[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        _, final_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dynamic_rnn(lstm_layers[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], input_tensor, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; final_state[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; output
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算余弦相似度：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name_scope(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;calu_cos_similarity&amp;#39;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#user_item和postive_item的相似度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#||user_norm|| = sqrt(sum(each ^ 2))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; user_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;square(user_dense_output), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keep_dims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#||pos_norm|| = sqrt(sum(each ^ 2))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; pos_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;square(pos_dense_output), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keep_dims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#  user_dense_output * pos_dense_output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; user_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(user_dense_output, pos_dense_output), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keep_dims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#||user_norm|| * ||pos_norm||，作为相似度的分母 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; user_pos_norm_prod &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(user_norm, pos_norm)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#用户item输出和正样本输出的相似度R(user, pos)，R_user_pos = (user_dense_output * pos_dense_output) / ||user_norm|| * ||pos_norm||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; R_user_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;truediv(user_pos, user_pos_norm_prod)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#||neg_norm|| = sqrt(sum(each ^ 2))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; neg_norm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;square(neg_dense_output), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keep_dims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#user_neg = user_dense_output * neg_dense_output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; user_neg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(user_dense_output, neg_dense_output), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keep_dims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#||user_norm|| * ||neg_norm||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; user_neg_norm_prod &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(user_norm, neg_norm)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#用户item输出和负样本输出的相似度R(user, neg)，R_user_neg = (user_dense_output * neg_dense_output) / ||user_norm|| * ||neg_norm||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; R_user_neg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;truediv(user_neg, user_neg_norm_prod)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算后验概率：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name_scope(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;calc_posterior_probability&amp;#39;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#exp(gamma * R(User, item))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;GAMMA &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;exp_R_user_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(GAMMA, R_user_pos))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;exp_R_user_neg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(GAMMA, R_user_neg))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#sum_exp_R = exp(gamma * R_user_pos) + exp(gamma * R_user_neg)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sum_exp_R &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(exp_R_user_pos, exp_R_user_neg)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#p(pos | user) = exp_R_user_pos / sum_exp_R&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;prob_pos_user &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;truediv(exp_R_user_pos, sum_exp_R)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#p(neg | user) = exp_R_user_neg / sum_exp_R&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# prob_neg_user = tf.truediv(exp_R_user_neg, sum_exp_R)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;损失函数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name_scope(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss_function&amp;#39;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# loss = -log(p(item_1 | user) * ... * p(item_n | user)),约束条件:item_i 属于被激活的item&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; log_prob_pos_user &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_by_value(prob_pos_user, &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# log_prob_neg_user = tf.log(tf.clip_by_value(prob_neg_user, 1e-6, 1.0))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# loss = -tf.reduce_sum(tf.add(log_prob_pos_user, log_prob_neg_user))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce_sum(log_prob_pos_user)    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# tf.summary.scalar(&amp;#39;loss&amp;#39;, loss)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练模型：训练得到的loss要除以batch size，以得到每个输入样本的loss。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于tensorflow中LSTM输出：返回的&lt;code&gt;final_states&lt;/code&gt;是个二元组(LSTMCell的参数&lt;code&gt;state_is_tuple=Tru&lt;/code&gt;e时才返回二元组，默认为true)，state[0]是cell state，final_states[1]是hidden state，可以取&lt;code&gt;hidden state&lt;/code&gt;作为lstm的输出（即&lt;code&gt;output = final_states[1]&lt;/code&gt;），对于多层lstm网络，取最后一个时间序列的final_state作为输出，即是&lt;code&gt;output = final_states[-1][1]&lt;/code&gt;。返回的outputs是记录的每一次的时间序列的输出，对于某些问题（如翻译），需要得到每次时间序列的lstm输出。对于LSTM后还接一个全连接层的模型，可以取所有时间序列的output作为全连接层的输入，&lt;code&gt;output = tf.reshape(outputs&lt;/code&gt;,&lt;code&gt; [-1,lstm_unit]&lt;/code&gt;)，&lt;code&gt;lstm_unit&lt;/code&gt;为LSTM的隐藏神经单元个数。一般地，&lt;code&gt;batch size = 1&lt;/code&gt;时，&lt;code&gt;final_states.shape = (1, lstm_unit)&lt;/code&gt;，&lt;code&gt;outputs.shape = (1, max_time, lstm_unit)&lt;/code&gt;，&lt;code&gt;final_states[1][0] = outputs[0][-1]&lt;/code&gt;，即是&lt;code&gt;final_state&lt;/code&gt;记录了每一条样本输出outputs的最后一次时间序列的输出。
&lt;img src=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p3.png&#34;
	width=&#34;1002&#34;
	height=&#34;695&#34;
	srcset=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p3_hu_ff3f51de2d91a324.png 480w, https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p3_hu_c25568175f81f26e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;训练过程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算召回率：模型训练好之后，使用测试数据集计算召回率。
a. 每次取一个用户（该用户必须在训练集和测试都有行为数据），给定一个估计集中最少推荐电影个数m。
b. 根据用户在训练集中交互过的电影中找出候选顶点，候选顶点：对用户在训练集中交互过的所有电影，找出每个电影顶点的孩子顶点（仅获取一层）、兄弟顶点和所有父顶点的孩子顶点（不包括父顶点本身），最后取并集，得到候选顶点，如若候选顶点不足m个，则从所有顶点中随机取若干个顶点补足m个，这m个电影顶点作为模型的正样本输入。
c. 根据训练好的模型计算用户信息和正样本的cos相似度SP，根据相似度SP从大到小排序，取前top k个顶点集，这k个顶点集和该用户的测试集中电影顶点集test_set取交集，记交集为i_set.
d. 该用户的召回率 = len(i_set) / len(test_set)。最后求所有用户的平均召回率（图中仅仅展示求得的召回率，并没有算出评价召回率）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/recall_rate.png&#34;
	width=&#34;1440&#34;
	height=&#34;720&#34;
	srcset=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/recall_rate_hu_bccbe7ee870030b5.png 480w, https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/recall_rate_hu_b626e89258e64541.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;召回率&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;模型改进：损失函数加入约束项，防止用户信息与正样本的相似度、用户信息与负样本的相似度过快收敛。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p4.png&#34;
	width=&#34;399&#34;
	height=&#34;146&#34;
	srcset=&#34;https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p4_hu_407bb8dd287b774e.png 480w, https://charent.github.io/post/%E5%AD%98%E5%9C%A8%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/p4_hu_9086b8262218e776.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;loss_function&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;273&#34;
		data-flex-basis=&#34;655px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
