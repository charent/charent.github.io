---
title: 负样本（负采样）
# description: 
date: 2019-12-19
# slug: 
# image: 
categories:
    - 机器学习
    - 深度学习
---

# 负采样
自然语言处理领域中，判断两个单词是不是一对上下文词（context）与目标词（target），如果是一对，则是正样本，如果不是一对，则是负样本。
采样得到一个上下文词和一个目标词，生成一个正样本（positive example），生成一个负样本（negative example），则是用与正样本相同的上下文词，再在字典中随机选择一个单词，这就是负采样（negative sampling）。


负采样是为了解决类别太多的一种折中方案，样本只是给模型训练提供信息的，那负样本的选择肯定是选信息量大的那些，比如一些模型的决策边界，如果有充足的样本就能学的比较好，如果负样本离分离边界太远，那其实提供不了太多有用信息，甚至会误导模型使其有偏。 

还有就是一些任务比如预测任务，负采样可能会使其偏度较大，比如点击率预估，本来样本点击率为0.01，负采样使正负样本比例1:9，那最后样本平均点击率就为0.1，这种任务如果一定要负采样肯定要进行一定的修正。
如果是一般的任务，其实负样本选择对效果的影响很大。主要看数据分布，分布波动较大，样本噪声高的任务，负采样很难。
其原理就是正常正负样本对参数影响的原理。而且一般都不是随机负采样，都是按照一定权重方法采样，进而也揭示了负采样其实不能随便采。

negative sampling在以下几种情况可能会有不一样的结果。
   1. 样本信息过分冗余，通过negative sampling可以在相同机器资源的情况下提高训练速度，而且对效果影响很有限，这对于有限预算下是很重要的。
   2. 负样本不能有效反应用户真实意图的情况下，negative sampling可能会带来收益，比如有一些场景用户很可能大部分都没有看到而导致的负样本采集；
   3. 对于不同的问题也可能会不太一样，比如说implicit和explicit的问题，implict的feedback本身也是有折损的，也就是不点击不代表不喜欢，点击也不代表一定喜欢，需要考虑的信号就需要更仔细的看了。
